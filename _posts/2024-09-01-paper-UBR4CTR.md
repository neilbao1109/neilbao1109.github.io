---
title: User Behavior Retrieval for Click-Through Rate Prediction
date: 2024-09-01 13:00:00 +0800
categories: [Paper, Ad Click Prediction]
tags: [ubr]
render_with_liquid: false
---

《User Behavior Retrieval for Click-Through Rate Prediction》（简称 **UBR4CTR**）是在 2020 年（SIGIR 会议）发表的论文。

这篇论文的出现，标志着推荐系统从“复杂的序列建模（如 DIN/DIEN）”转向了**“超长序列的检索式建模”**。它解决了一个工程与算法的终极矛盾：**想利用用户极其漫长的历史行为（如数千条），但模型推理速度又不能变慢。**


---

### 1. 核心痛点：DIN 和 DIEN 算不过来了

在 UBR4CTR 之前，DIN 和 DIEN 虽然效果好，但存在一个致命的**性能瓶颈**：

* **计算复杂度是线性的**：如果用户历史行为序列长度是 ，DIN 的 Attention 机制就要计算  次。
* **现实困境**：在电商平台，活跃用户几年的历史行为可能多达几千甚至上万条。
* 如果 （截断），会丢失用户长期的兴趣（比如去年买过冰箱，今年想买滤芯）。
* 如果 ，在线推理（Inference）会有几十毫秒的延迟，这是系统无法承受的。



**UBR4CTR 的核心思想：**
不要把所有历史行为都塞进模型里计算！**把“预测”问题转化为“检索”问题**。
在预测点击率之前，先用一个低成本的“搜索引擎”，从用户成千上万的历史行为中，**捞出**与当前目标商品最相关的 Top-K 个行为，然后再送给深度模型。

---

### 2. 模型架构：检索 + 预测 (Retrieval + Prediction)

UBR4CTR 将整个 CTR 预测过程拆分为两个解耦的模块：

#### A. 用户行为检索模块 (User Behavior Retrieval Module)

这是论文的核心创新。

* **目标**：从巨大的历史序列  中，快速筛选出子序列 。
* **做法**：它不再逐一计算 Attention，而是采用**近似最近邻搜索（ANN, Approximate Nearest Neighbor）** 或 **倒排索引** 的思想。
* 将目标商品（Target Item）作为 **Query**。
* 将用户的历史行为看作 **Documents**。
* 通过预训练的 Embedding 空间，快速找到距离最近的  个历史行为。



#### B. 预测模块 (Prediction Module)

* **做法**：这一步和 DIN 非常相似。
* **输入**：检索出来的  个行为（通常  很小，比如 10-20）。
* **计算**：使用 Attention 机制对这  个行为进行精细化建模，最后输出 CTR。
* **优势**：因为  很小，所以这一步计算非常快，哪怕原始历史长度是 10000 也没关系。

---

### 3. 关键挑战：检索与预测的“隔阂”

把模型拆成两段会遇到一个巨大的问题：**怎么训练？**

* 通常的“检索（召回）”是用相关性标签训练的。但在 CTR 任务中，我们没有标签告诉模型“哪一条历史行为最有用”。
* 我们只有最终的“点/不点”标签。如果检索模块选错了行为，预测模块就得不到好结果，但梯度很难传回给检索模块（因为检索通常包含不可导的排序/TopK 操作）。

**UBR4CTR 的解决方案：学习式检索 (Learnable Retrieval)**
论文提出了一种基于 **Gumbel-Softmax** 或 **强化学习** 思路的优化方法，试图打通这两者，让最终的 CTR 损失函数能够指导检索模块的参数更新。

* *通俗解释*：模型不仅学“怎么打分”，还学“怎么挑数据”。如果挑出的历史行为让预测更准了，检索模块就会受到奖励。

---

### 4. 行业影响与演进：SIM 模型

提到 UBR4CTR，就必须提到与其几乎同时期（或稍晚）出现的 **SIM (Search-based Interest Model)**，也是阿里发表的。它们思路非常像，共同定义了**“长序列建模”**的标准范式。

* **UBR4CTR** 侧重于提出“检索”这个概念，并尝试解决端到端训练的难题。
* **SIM (Search-based Interest Model)** 则更加工程化和直接：
* **Hard Search**：直接用商品的**类目（Category）**做索引。比如目标商品是“耐克鞋”，直接去历史里把所有“鞋类”行为捞出来。简单粗暴，但在工业界极其有效。
* **Soft Search**：使用向量检索（Faiss 等库）加速。



---

### 5. 为什么 UBR4CTR 很重要？

1. **突破了长度限制**：让模型能够处理 **Lifetime（终身）** 级别的用户行为序列。
2. **性能与效果的平衡**：它证明了我们不需要对所有数据进行深层计算，**“相关性检索”是注意力的预筛选**。
3. **长期兴趣的激活**：解决了“低频复购”商品的推荐问题（比如耐用品、节日用品），因为这些兴趣点往往埋藏在很久远的历史中，只有通过检索才能找回来。

---

### 总结

**UBR4CTR 把推荐系统变成了一个“搜索引擎”。**

* **以前 (DIN/DIEN)**：像是一个勤奋的图书管理员，每次你问问题，他都要把你的阅读记录**从头到尾读一遍**，然后分析你的喜好。
* **现在 (UBR4CTR/SIM)**：图书管理员学会了**查索引**。你问“运动鞋”，他直接去索引里搜你以前关于“运动”的记录，只读那几页，既快又准。
