---
title: DeepFM 
date: 2024-12-05 10:00:00 +0800
categories: [Paper, Ad Click Prediction]
tags: [deepfm]
render_with_liquid: false
---

《DeepFM: A Factorization-Machine based Neural Network for CTR Prediction》是由**华为诺亚方舟实验室**在 2017 年提出的经典模型。

在推荐系统和广告点击率（CTR）预测的发展史上，DeepFM 的地位非常高，因为它完美解决了如何同时兼顾“低阶特征组合”和“高阶特征组合”的问题，且**实现了真正的端到端自动化特征工程**。

---

### 1. 核心思想：为什么要“Deep + FM”？

在 CTR 预测中，特征交叉是成功的关键。

* **低阶交叉（1阶、2阶）**：比如“用户下载了 APP A”和“用户下载了 APP B”这两个特征的组合（FM 擅长）。
* **高阶交叉（3阶及以上）**：更深层、更复杂的非线性关系（DNN 擅长）。

**DeepFM 的突破：**
早期的 **Wide & Deep** 模型虽然也结合了两者，但它的 Wide 部分需要专家手动设计特征交叉。而 DeepFM 提出：**用 FM（因子分解机）替换 Wide 部分，让模型自动学习所有阶数的交叉，彻底解放双手。**

---

### 2. 模型架构详解

DeepFM 由两个主要部分组成，它们共享同一个 **Embedding 层**：

#### A. FM 部分（Factorization Machine）

负责建模 **1 阶（线性）** 和 **2 阶（特征对）** 的显式交叉。

* **公式推导**：


* 其中  是两个特征向量的内积。


* **作用**：即便某些特征组合在训练集中从未出现过，FM 也能通过向量内积计算出它们的权重，解决了数据稀疏性问题。

#### B. Deep 部分（DNN）

负责建模 **高阶** 的隐式交叉。

* 它将 Embedding 后的向量拼接起来，通过多层全连接网络（ReLU 激活），提取更抽象、更深层的信息。

#### C. 共享 Embedding 层（最精妙的设计）

DeepFM 的 FM 部分和 Deep 部分**共享同一套特征嵌入向量（Shared Embeddings）**。

* **意义**：这样做的好处是，Embedding 向量既受低阶交叉的影响，也受高阶交叉的影响。模型训练更高效，且减少了参数量，避免了不同部分由于 Embedding 空间不一致导致的预测偏差。

---

### 3. DeepFM 的四大优势

1. **无需人工特征工程**：模型会自动学习低阶和高阶特征组合。
2. **同时学习两种逻辑**：既有 FM 带来的强大记忆能力（Memorization），也有 DNN 带来的泛化能力（Generalization）。
3. **共享 Embedding**：不仅提高了训练速度，还增强了模型的特征表达能力。
4. **端到端训练**：模型结构简单且统一，易于在大规模工业环境中部署。

---

### 4. 与其他模型的对比

* **vs. Wide & Deep**：Wide & Deep 的 Wide 端需要手动构造交叉特征（如 ），而 DeepFM 用 FM 自动完成了这一步。
* **vs. FNN/PNN**：FNN 依赖 FM 预训练，不是端到端；PNN 主要侧重高阶交叉，而忽略了低阶线性关系。DeepFM 则是这两者的集大成者。

---

### 总结

DeepFM 是工业界应用最广泛的 CTR 模型之一。它通过一个简洁的并行结构，成功地将 FM 的解释性/鲁棒性与 DNN 的高阶拟合能力结合在一起。
